<<<<<<< HEAD
=======
<<<<<<< HEAD
# first data transformation
X = log(prepsloc)
Y = log(defsloc)
# plot the transformed data
plot(X, Y,
xlab = "Log PrepTime/SLOC",
ylab = "Log Defects/SLOC"
)
n <- 100
mu <- c(-2, 2)
sigma <- matrix(c(1, 0.5, 0.5, 1), nrow = 2)
n
mu
sigma
library(MASS)
set.seed(123)
head(X)
X <- mvrnorm(n, mu, sigma)
#plot(X[, 1], X[, 2])
source("../R/matlab.R")
# read the matrix from Matlab table
x_table <- read.csv('table.csv', header = FALSE)
# convert to matrix
X <- as.matrix(x_table)
xbar <- colMeans(X)   # calculate the means of the columns
# get the eigenvectors and eigenvalues of the covariance matrix
eig <- mlab_eig(cov(X))  # calculate the eigenVv of the covariance of X
D <- eig$D
V <- eig$V
# center the data
Xc <- X - matrix(1, n, 1) %*% xbar
# Sphere the data
z <- D %^% (-1/2) %*% t(V) %*% t(Xc)  # using a custom built ^ operator
Z <- t(z)                             # transpose to plot
plot(Z[, 1], Z[, 2])
source("/R/matlab.R")
# read the matrix from Matlab table
x_table <- read.csv('table.csv', header = FALSE)
# convert to matrix
X <- as.matrix(x_table)
xbar <- colMeans(X)   # calculate the means of the columns
# get the eigenvectors and eigenvalues of the covariance matrix
eig <- mlab_eig(cov(X))  # calculate the eigenVv of the covariance of X
D <- eig$D
V <- eig$V
# center the data
Xc <- X - matrix(1, n, 1) %*% xbar
# Sphere the data
z <- D %^% (-1/2) %*% t(V) %*% t(Xc)  # using a custom built ^ operator
Z <- t(z)                             # transpose to plot
plot(Z[, 1], Z[, 2])
getwd()
wd <- getwd()
source(paste(wd, "/R/matlab.R"))
# read the matrix from Matlab table
x_table <- read.csv('table.csv', header = FALSE)
# convert to matrix
X <- as.matrix(x_table)
xbar <- colMeans(X)   # calculate the means of the columns
# get the eigenvectors and eigenvalues of the covariance matrix
eig <- mlab_eig(cov(X))  # calculate the eigenVv of the covariance of X
D <- eig$D
V <- eig$V
# center the data
Xc <- X - matrix(1, n, 1) %*% xbar
# Sphere the data
z <- D %^% (-1/2) %*% t(V) %*% t(Xc)  # using a custom built ^ operator
Z <- t(z)                             # transpose to plot
plot(Z[, 1], Z[, 2])
wd <- getwd()
source(paste0(wd, "/R/matlab.R"))
# read the matrix from Matlab table
x_table <- read.csv('table.csv', header = FALSE)
# convert to matrix
X <- as.matrix(x_table)
xbar <- colMeans(X)   # calculate the means of the columns
# get the eigenvectors and eigenvalues of the covariance matrix
eig <- mlab_eig(cov(X))  # calculate the eigenVv of the covariance of X
D <- eig$D
V <- eig$V
# center the data
Xc <- X - matrix(1, n, 1) %*% xbar
# Sphere the data
z <- D %^% (-1/2) %*% t(V) %*% t(Xc)  # using a custom built ^ operator
Z <- t(z)                             # transpose to plot
plot(Z[, 1], Z[, 2])
paste0(wd, "cc")
wd
getwd()
wd <- getwd()
script.dir <- dirname(sys.frame(1)$ofile)
script.dir <- dirname(sys.frame(1)$ofile)
script.dir <- dirname(sys.frame(1)$ofile)
ofile
dirname()
sys.frame()
sys.frame(1)
sys.frame(0)
sys.frame(2)
source(paste0("../../R/matlab.R")
# read the matrix from Matlab table
x_table <- read.csv('table.csv', header = FALSE)
# convert to matrix
X <- as.matrix(x_table)
xbar <- colMeans(X)   # calculate the means of the columns
# get the eigenvectors and eigenvalues of the covariance matrix
eig <- mlab_eig(cov(X))  # calculate the eigenVv of the covariance of X
D <- eig$D
V <- eig$V
# center the data
Xc <- X - matrix(1, n, 1) %*% xbar
# Sphere the data
z <- D %^% (-1/2) %*% t(V) %*% t(Xc)  # using a custom built ^ operator
Z <- t(z)                             # transpose to plot
plot(Z[, 1], Z[, 2])
source("../../R/matlab.R")
# read the matrix from Matlab table
x_table <- read.csv('table.csv', header = FALSE)
# convert to matrix
X <- as.matrix(x_table)
xbar <- colMeans(X)   # calculate the means of the columns
# get the eigenvectors and eigenvalues of the covariance matrix
eig <- mlab_eig(cov(X))  # calculate the eigenVv of the covariance of X
D <- eig$D
V <- eig$V
# center the data
Xc <- X - matrix(1, n, 1) %*% xbar
# Sphere the data
z <- D %^% (-1/2) %*% t(V) %*% t(Xc)  # using a custom built ^ operator
Z <- t(z)                             # transpose to plot
plot(Z[, 1], Z[, 2])
sessionInfo()
# read the matrix from Matlab table
x_table <- read.csv('table.csv', header = FALSE)
# convert to matrix
X <- as.matrix(x_table)
xbar <- colMeans(X)   # calculate the means of the columns
# get the eigenvectors and eigenvalues of the covariance matrix
eig <- eigen(cov(X))  # calculate the eigenVv of the covariance of X
# shift the columns in the eigenvectors as in Matlab
V <- eig$vectors
VV <- V[, 2:1]
# square root of the diagonal of eigenvalues withut infinite
eigen_values <- eig$values
eigen_values_mlab <- rev(eigen_values)   # reverse the eigen values as in Matlab
D <- diag(eigen_values_mlab)
DD <- diag((diag(D))^(-1/2))
# center the data
Xc <- X - matrix(1, n, 1) %*% xbar
# Sphere the data
z <- DD %*% t(VV) %*% t(Xc)
Z <-t(z)                    # transpose to plot
plot(Z[, 1], Z[, 2])
source("../matlab.R")
# read the matrix from Matlab table
x_table <- read.csv('table.csv', header = FALSE)
# convert to matrix
X <- as.matrix(x_table)
eig_ret <- mlab_eig(cov(X))
eig_ret
source("../R/matlab.R")
# read the matrix from Matlab table
x_table <- read.csv('table.csv', header = FALSE)
# convert to matrix
X <- as.matrix(x_table)
xbar <- colMeans(X)   # calculate the means of the columns
# get the eigenvectors and eigenvalues of the covariance matrix
eig <- mlab_eig(cov(X))  # calculate the eigenVv of the covariance of X
D <- eig$D
V <- eig$V
# center the data
Xc <- X - matrix(1, n, 1) %*% xbar
# Sphere the data
z <- D %^% (-1/2) %*% t(V) %*% t(Xc)  # using a custom built ^ operator
Z <- t(z)                             # transpose to plot
plot(Z[, 1], Z[, 2])
library(Rcpp)
sourceCpp("src/MatrixExample.cpp")
library(Rcpp)
sourceCpp("../src/MatrixExample.cpp")
library(Rcpp)
sourceCpp("../../src/MatrixExample.cpp")
M <- matrix((1:16)^2, 4)
class(M)
ME <- MatrixExample(M)
class(ME)
ME
library(Rcpp)
myroot <- cppFunction('double myroot(double x) { return ::sqrt(x); }')
myroot(16)
library(Rcpp)               ## recent version for sourceCpp()
sourceCpp("../../src/eigenEx.cpp")    ## converts source file into getEigen() we can call
knitr::opts_chunk$set(echo = TRUE, comment = NA, error = TRUE)
library(knitr)
opts_chunk$set(fig.align='center', fig.path='Rcpp/', warning=FALSE, message=FALSE, echo=TRUE)
library(Rcpp)
fibR <- function(n){
## I commented this out because I am not handling errors in the C++ code,
## so the code is comparable
# if (n < 0) {
#  stop("Argument n must be non-negative integer.\n")
# } else
if (n == 0) {
return(0)
} else if (n == 1) {
return(1)
} else {
Recall(n-1) + Recall(n-2)
}
}
n <- 10:26
time.to.calculate <- sapply(n, function(x) system.time(fibR(x))[3])
plot(n, time.to.calculate, xlab="n", ylab="seconds",
main="Fibonacci F calculation time", type="b")
library(Rcpp)
dyn.load("fibWrap.so")
.Call("fibWrapper", 5) # Evaluates fibWrapper() at 5
.Call("fibWrapper", 9)
.Call("fibWrapper", 10)
library(Rcpp)
sourceCpp("src/fibBest.cpp")
n2 <- 10:(26+12) # Some extra 12 values
time.to.calculateCpp <- sapply(n2, function(x) system.time(fibCpp(x))[3])
plot(n2, c(time.to.calculate, rep(NA,12)), xlab="n", ylab="seconds",
main="Fibonacci F calculation time", type="b")
lines(n2, time.to.calculateCpp, type="b", col="Red")
legend("topleft", inset=0.01, legend=c("R","C++"), pch=1, col=1:2)
library(Rcpp)
sourceCpp("src/dnormCpp.cpp")
all.equal(dnorm(1:10, 5, 1), dnormCpp(1:10, 5,1))
n <- 20
timeCpp <- timeR <- numeric(n)
for(k in 1:n){
timeCpp[k] <- system.time({dnormCpp(1:(10000*n), 10000*n/2, 10000*n)})[3]
timeR[k] <- system.time({dnorm(1:(10000*n), 10000*n/2, 10000*n)})[3]
}
plot(10000*(1:n), timeR, xlab="n", ylab="seconds", ylim=c(0, max(timeR)),
main="dnorm() v. dnormCpp() times", type="b")
lines(10000*(1:n), timeCpp, type="b", col="Green")
legend("bottomleft", inset=0.01, legend=c("R","C++"), pch=1, col=c("Black", "Green"))
require(RcppEigen)
sourceCpp("src/xtSx.cpp")
S <- matrix(c(1,.5,.5,1),ncol=2)
Y <- c(3,2)
X <- matrix(c(1,0,1,1), ncol=2)
solve(t(X)%*%solve(S)%*%X)%*%t(X)%*%solve(S)%*%Y
xtSx(X,S,Y)
xtSxR <- function(X, S, Y){
return(solve(t(X)%*%solve(S)%*%X)%*%t(X)%*%solve(S)%*%Y)
}
xtSxRclever <- function(X, S, Y){
return(solve(crossprod(X, solve(S, X)), crossprod(X, solve(S, Y))))
}
p <- 10
n <- seq(200, 500, by=20)
timeCpp <- numeric(length(n))
timeR <- numeric(length(n))
timeRclever <- numeric(length(n))
k <- 0
set.seed(1)
for(i in n){
k <- k + 1
Y <- rnorm(i)
X <- matrix(rnorm(i*p), ncol=p)
S <- matrix(0, i, i)
for(j in 1:i){
S[j,] = 0.5^abs(j - 1:i)
}
timeCpp[k] <- system.time(xtSx(X,S,Y))[3]
timeR[k] <- system.time(xtSxR(X,S,Y))[3]
timeRclever[k] <- system.time(xtSxRclever(X,S,Y))[3]
}
plot(n, timeR, xlab="n", ylab="seconds", ylim=c(0, max(timeR)),
main="Generalized LS calculation time", type="b")
lines(n, timeRclever, type="b", col="Red")
lines(n, timeCpp, type="b", col="Blue")
legend("topleft", inset=0.01, legend=c("R","Rclever","C++"), pch=1, col=c("Black", "Red", "Blue"))
all.equal(as.numeric(xtSx(X,S,Y)),
as.numeric(xtSxR(X,S,Y)),
as.numeric(xtSxRclever(X,S,Y)))
sourceCpp("src/xtSxMod.cpp")
timeCppFast <- numeric(length(n))
k <- 0
set.seed(1)
for(i in n){
k <- k + 1
Y <- rnorm(i)
X <- matrix(rnorm(i*p), ncol=p)
S <- matrix(0, i, i)
for(j in 1:i){
S[j,] = 0.5^abs(j - 1:i)
}
timeCppFast[k] <- system.time(xtSxMod(X,S,Y))[3]
}
plot(n, timeR, xlab="n", ylab="seconds", ylim=c(0, max(timeR)),
main="Generalized LS calculation time", type="b")
lines(n, timeRclever, type="b", col="Red")
lines(n, timeCpp, type="b", col="Blue")
lines(n, timeCppFast, type="b", col="Orange")
legend("topleft", inset=0.01, legend=c("R","R Fast","C++","C++ Fast"), pch=1, col=c("Black", "Red", "Blue", "Orange"))
library(Rcpp)
sourceCpp("src/dnormCpp.cpp")
all.equal(dnorm(1:10, 5, 1), dnormCpp(1:10, 5,1))
n <- 20
timeCpp <- timeR <- numeric(n)
for(k in 1:n){
timeCpp[k] <- system.time({dnormCpp(1:(10000*n), 10000*n/2, 10000*n)})[3]
timeR[k] <- system.time({dnorm(1:(10000*n), 10000*n/2, 10000*n)})[3]
}
plot(10000*(1:n), timeR, xlab="n", ylab="seconds", ylim=c(0, max(timeR)),
main="dnorm() v. dnormCpp() times", type="b")
lines(10000*(1:n), timeCpp, type="b", col="Green")
legend("bottomleft", inset=0.01, legend=c("R","C++"), pch=1, col=c("Black", "Green"))
library(Rcpp)
sourceCpp("../../src/dnormCpp.cpp")
all.equal(dnorm(1:10, 5, 1), dnormCpp(1:10, 5,1))
n <- 20
timeCpp <- timeR <- numeric(n)
for(k in 1:n){
timeCpp[k] <- system.time({dnormCpp(1:(10000*n), 10000*n/2, 10000*n)})[3]
timeR[k] <- system.time({dnorm(1:(10000*n), 10000*n/2, 10000*n)})[3]
}
plot(10000*(1:n), timeR, xlab="n", ylab="seconds", ylim=c(0, max(timeR)),
main="dnorm() v. dnormCpp() times", type="b")
lines(10000*(1:n), timeCpp, type="b", col="Green")
legend("bottomleft", inset=0.01, legend=c("R","C++"), pch=1, col=c("Black", "Green"))
require(RcppEigen)
sourceCpp("../../src/xtSx.cpp")
S <- matrix(c(1,.5,.5,1),ncol=2)
Y <- c(3,2)
X <- matrix(c(1,0,1,1), ncol=2)
solve(t(X)%*%solve(S)%*%X)%*%t(X)%*%solve(S)%*%Y
xtSx(X,S,Y)
xtSxR <- function(X, S, Y){
return(solve(t(X)%*%solve(S)%*%X)%*%t(X)%*%solve(S)%*%Y)
}
xtSxRclever <- function(X, S, Y){
return(solve(crossprod(X, solve(S, X)), crossprod(X, solve(S, Y))))
}
p <- 10
n <- seq(200, 500, by=20)
timeCpp <- numeric(length(n))
timeR <- numeric(length(n))
timeRclever <- numeric(length(n))
k <- 0
set.seed(1)
for(i in n){
k <- k + 1
Y <- rnorm(i)
X <- matrix(rnorm(i*p), ncol=p)
S <- matrix(0, i, i)
for(j in 1:i){
S[j,] = 0.5^abs(j - 1:i)
}
timeCpp[k] <- system.time(xtSx(X,S,Y))[3]
timeR[k] <- system.time(xtSxR(X,S,Y))[3]
timeRclever[k] <- system.time(xtSxRclever(X,S,Y))[3]
}
plot(n, timeR, xlab="n", ylab="seconds", ylim=c(0, max(timeR)),
main="Generalized LS calculation time", type="b")
lines(n, timeRclever, type="b", col="Red")
lines(n, timeCpp, type="b", col="Blue")
legend("topleft", inset=0.01, legend=c("R","Rclever","C++"), pch=1, col=c("Black", "Red", "Blue"))
all.equal(as.numeric(xtSx(X,S,Y)),
as.numeric(xtSxR(X,S,Y)),
as.numeric(xtSxRclever(X,S,Y)))
sourceCpp("../../src/xtSxMod.cpp")
timeCppFast <- numeric(length(n))
k <- 0
set.seed(1)
for(i in n){
k <- k + 1
Y <- rnorm(i)
X <- matrix(rnorm(i*p), ncol=p)
S <- matrix(0, i, i)
for(j in 1:i){
S[j,] = 0.5^abs(j - 1:i)
}
timeCppFast[k] <- system.time(xtSxMod(X,S,Y))[3]
}
plot(n, timeR, xlab="n", ylab="seconds", ylim=c(0, max(timeR)),
main="Generalized LS calculation time", type="b")
lines(n, timeRclever, type="b", col="Red")
lines(n, timeCpp, type="b", col="Blue")
lines(n, timeCppFast, type="b", col="Orange")
legend("topleft", inset=0.01, legend=c("R","R Fast","C++","C++ Fast"), pch=1, col=c("Black", "Red", "Blue", "Orange"))
PKG_CXXFLAGS=`Rscript -e 'Rcpp:::CxxFlags()'` \
PKG_LIBS=`Rscript -e 'Rcpp:::LdFlags()'`  \
R CMD SHLIB fibWrap.cpp
library(Rcpp)
dyn.load("fibWrap.so")
.Call("fibWrapper", 5) # Evaluates fibWrapper() at 5
.Call("fibWrapper", 9)
.Call("fibWrapper", 10)
library(Rcpp)
sourceCpp("../../src/fibBest.cpp")
n2 <- 10:(26+12) # Some extra 12 values
time.to.calculateCpp <- sapply(n2, function(x) system.time(fibCpp(x))[3])
plot(n2, c(time.to.calculate, rep(NA,12)), xlab="n", ylab="seconds",
main="Fibonacci F calculation time", type="b")
lines(n2, time.to.calculateCpp, type="b", col="Red")
legend("topleft", inset=0.01, legend=c("R","C++"), pch=1, col=1:2)
#include <Rcpp.h>
#include <cmath>        // std::exp(double)
#include <valarray>     // std::valarray, std::exp(valarray)
using namespace Rcpp;
// [[Rcpp::export]]
NumericVector dnormCpp(NumericVector x, double mu, double sigma) {
// const double MYPI = 3.141592;
// I think PI is available in cmath
int n = x.size();
NumericVector d(n);
NumericVector ret(n);
for(int i = 0; i < n; i++){
d[i] = (x[i] - mu)/sigma;
d[i] *= d[i];
ret[i] = exp(-0.5*d[i])/(sqrt(2*PI)*sigma);
}
return(ret);
}
library(Rcpp)
sourceCpp("../../src/dnormCpp.cpp")
all.equal(dnorm(1:10, 5, 1), dnormCpp(1:10, 5,1))
n <- 20
timeCpp <- timeR <- numeric(n)
for(k in 1:n){
timeCpp[k] <- system.time({dnormCpp(1:(10000*n), 10000*n/2, 10000*n)})[3]
timeR[k] <- system.time({dnorm(1:(10000*n), 10000*n/2, 10000*n)})[3]
}
plot(10000*(1:n), timeR, xlab="n", ylab="seconds", ylim=c(0, max(timeR)),
main="dnorm() v. dnormCpp() times", type="b")
lines(10000*(1:n), timeCpp, type="b", col="Green")
legend("bottomleft", inset=0.01, legend=c("R","C++"), pch=1, col=c("Black", "Green"))
require(RcppEigen)
sourceCpp("../../src/xtSx.cpp")
S <- matrix(c(1,.5,.5,1),ncol=2)
Y <- c(3,2)
X <- matrix(c(1,0,1,1), ncol=2)
solve(t(X)%*%solve(S)%*%X)%*%t(X)%*%solve(S)%*%Y
xtSx(X,S,Y)
fibR <- function(n){
## I commented this out because I am not handling errors in the C++ code,
## so the code is comparable
# if (n < 0) {
#  stop("Argument n must be non-negative integer.\n")
# } else
if (n == 0) {
return(0)
} else if (n == 1) {
return(1)
} else {
Recall(n-1) + Recall(n-2)
}
}
n <- 10:26
time.to.calculate <- sapply(n, function(x) system.time(fibR(x))[3])
plot(n, time.to.calculate, xlab="n", ylab="seconds",
main="Fibonacci F calculation time", type="b")
knitr::opts_chunk$set(echo = TRUE, comment = NA, error = TRUE)
library(RcppEigen)
pkgVersion <- packageDescription("RcppEigen")$Version
pkgDate <- packageDescription("RcppEigen")$Date
pkgVersion
pkgDate
RcppSamp <- function(X) {
stopifnot(is.numeric(X <- as.matrix(X)),
(nc <- ncol(X)) > 1L,
all(X >= 0))
.Call(CppSamp, X)
}
library(Rcpp);
library(inline);
library(RcppEigen);
maxOverColCpp <- '
using Eigen::Map;
using Eigen::MatrixXd;
// Map the double matrix AA from R
const Map<MatrixXd> A(as<Map<MatrixXd> >(AA));
// evaluate and columnwise maximum entry of A
const MatrixXd Amax(A.colwise().maxCoeff());
return wrap(Amax);
'
rcppeigen_max_over_columns <- cxxfunction(signature(AA = "matrix"), maxOverColCpp, plugin = "RcppEigen")
M <- matrix(c(1,2,3,4,5,6,7,8,9), ncol=3)
M
rcppeigen_max_over_columns(M)
library(RcppEigen)
rcppeigen_max_over_columns3(M)
library(Rcpp);
library(inline);
library(RcppEigen);
transCpp <- '
using Eigen::Map;
using Eigen::MatrixXi;
// Map the integer matrix AA from R
const Map<MatrixXi> A (as<Map<MatrixXi> >(AA));
// evaluate and return the transpose of A
const MatrixXi
At(A.transpose());
return wrap(At);
'
ftrans <- cxxfunction(signature(AA = "matrix"), transCpp, plugin = "RcppEigen")
(A <- matrix(1:6, ncol = 2))
str(A)
(At <- ftrans(A))
require(RcppEigen)
B <- matrix(1:6, ncol = 2)
B
transCpp(B)
M <- matrix(c(1,2,3,4,5,6,7,8,9), ncol=3)
M
transCpp(M)
=======
# change iterations to 1001 and compute cost1001
beta <- (grad.descent(x,1001))
cost <- t(mat.or.vec(1,m))
for(i in 1:m) {
cost[i,1] <-  (1 /(2*m)) * (h(x[i,2],beta[1,1],beta[1,2])- y[i,])^2
}
cost1001 <- colSums(cost)
# does this difference meet your convergence criteria?
print(cost1000 - cost1001)
xs <- seq(0, 4,len=20) # create some values
# define the function we want to optimize
f <-  function(x) {
1.2 * (x-2)^2 + 3.2
}
# plot the function
plot(xs, f (xs),
type="l",
xlab="x",
ylab=expression(1.2(x-2)^2 +3.2))
# calculate the gradient df/dx
grad <- function(x){
1.2*2*(x-2)
}
# df/dx = 2.4(x-2), if x = 2 then 2.4(2-2) = 0
# The actual solution we will approximate with gradeint descent
# is  x = 2 as depicted in the plot below
lines (c (2,2), c (3,8), col="green", lty=2)          # vertical
text (2.1,7, "Closedform solution",col="red",pos=4)
# gradient descent implementation
x <- 0.1       # initialize the first guess for x-value
xtrace <- x    # store x -values for graphing purposes (initial)
ftrace <- f(x) # store y-values (function eval at x) for graphing purposes (initial)
stepFactor <- 0.6 # learning rate 'alpha'
for (step in 1:100) {
x <- x - stepFactor * grad(x) # gradient descent update
xtrace <- c(xtrace, x) # update for graph
ftrace <- c(ftrace, f(x)) # update for graph
}
lines (xtrace, ftrace, type="b", col="blue")
>>>>>>> 2bcf3c4e6653cee6ff3ff3fd1191080c10c6a506
text (0.5, 6, "Gradient Descent", col="blue",pos= 4)
# print final value of x
print(x) # x converges to 2.0
xs <- seq(0, 4,len=20) # create some values
# define the function we want to optimize
f <-  function(x) {
1.2 * (x-2)^2 + 3.2
}
# plot the function
plot(xs, f (xs),
type="l",
xlab="x",
ylab=expression(1.2(x-2)^2 +3.2))
# calculate the gradient df/dx
grad <- function(x){
1.2*2*(x-2)
}
# df/dx = 2.4(x-2), if x = 2 then 2.4(2-2) = 0
# The actual solution we will approximate with gradeint descent
# is  x = 2 as depicted in the plot below
lines (c(2,2), c(3,8), col="green", lty=2)          # vertical
text (2.1,7, "Closedform solution",col="red",pos=4)
# gradient descent implementation
x <- 0.1       # initialize the first guess for x-value
xtrace <- x    # store x -values for graphing purposes (initial)
ftrace <- f(x) # store y-values (function eval at x) for graphing purposes (initial)
stepFactor <- 0.6 # learning rate 'alpha'
for (step in 1:100) {
x <- x - stepFactor * grad(x) # gradient descent update
xtrace <- c(xtrace, x) # update for graph
ftrace <- c(ftrace, f(x)) # update for graph
}
lines (xtrace, ftrace, type="b", col="blue")
text (0.5, 6, "Gradient Descent", col="blue",pos= 4)
# print final value of x
print(x) # x converges to 2.0
xs <- seq(0, 4,len=20) # create some values
# define the function we want to optimize
f <-  function(x) {
1.2 * (x-2)^2 + 3.2
}
# plot the function
plot(xs, f (xs),
type="l",
xlab="x",
ylab=expression(1.2(x-2)^2 +3.2))
# calculate the gradient df/dx
grad <- function(x){
1.2*2*(x-2)
}
# df/dx = 2.4(x-2), if x = 2 then 2.4(2-2) = 0
# The actual solution we will approximate with gradeint descent
# is  x = 2 as depicted in the plot below
lines (c(2,2), c(3,8), col="green", lty=2)
text (2.1,7, "Closed-form solution", col="red", pos=4)
# gradient descent implementation
x <- 0.1       # initialize the first guess for x-value
xtrace <- x    # store x -values for graphing purposes (initial)
ftrace <- f(x) # store y-values (function eval at x) for graphing purposes (initial)
stepFactor <- 0.6 # learning rate 'alpha'
for (step in 1:100) {
x <- x - stepFactor * grad(x) # gradient descent update
xtrace <- c(xtrace, x) # update for graph
ftrace <- c(ftrace, f(x)) # update for graph
}
lines (xtrace, ftrace, type="b", col="blue")
text (0.5, 6, "Gradient Descent", col="blue",pos= 4)
# print final value of x
print(x) # x converges to 2.0
lines (xtrace, ftrace, type="b", col="blue")
plot()
plot(xs, f (xs))
lines (xtrace, ftrace, type="b", col="blue")
plot(xs, f (xs), xlim = c(1.5, 2.5))
lines (xtrace, ftrace, type="b", col="blue")
plot(xs, f (xs), xlim = c(1.9, 2.1))
lines (xtrace, ftrace, type="b", col="blue")
xs <- seq(0, 4,len=20) # create some values
# define the function we want to optimize
f <-  function(x) {
1.2 * (x-2)^2 + 3.2
}
# plot the function
plot(xs, f (xs),
type = "l",
xlab = "x",
ylab = expression(1.2(x-2)^2 +3.2))
# calculate the gradient df/dx
grad <- function(x){
1.2*2*(x-2)
}
# df/dx = 2.4(x-2), if x = 2 then 2.4(2-2) = 0
# The actual solution we will approximate with gradeint descent
# is  x = 2 as depicted in the plot below
lines (c(2,2), c(3,8), col="green", lty=2)
text (2.1,7, "Closed-form solution", col="red", pos=4)
# gradient descent implementation
x <- 0.1       # initialize the first guess for x-value
xtrace <- x    # store x -values for graphing purposes (initial)
ftrace <- f(x) # store y-values (function eval at x) for graphing purposes (initial)
stepFactor <- 0.6 # learning rate 'alpha'
for (step in 1:100) {
x <- x - stepFactor * grad(x) # gradient descent update
xtrace <- c(xtrace, x)      # update for graph
ftrace <- c(ftrace, f(x))   # update for graph
}
lines (xtrace, ftrace, type="b", col="blue")
text (0.5, 6, "Gradient Descent", col="blue", pos= 4)
# print final value of x
print(dim(xtrace))
print(x) # x converges to 2.0
xs <- seq(0, 4,len=20) # create some values
# define the function we want to optimize
f <-  function(x) {
1.2 * (x-2)^2 + 3.2
}
# plot the function
plot(xs, f (xs),
type = "l",
xlab = "x",
ylab = expression(1.2(x-2)^2 +3.2))
# calculate the gradient df/dx
grad <- function(x){
1.2*2*(x-2)
}
# df/dx = 2.4(x-2), if x = 2 then 2.4(2-2) = 0
# The actual solution we will approximate with gradeint descent
# is  x = 2 as depicted in the plot below
lines (c(2,2), c(3,8), col="green", lty=2)
text (2.1,7, "Closed-form solution", col="red", pos=4)
# gradient descent implementation
x <- 0.1       # initialize the first guess for x-value
xtrace <- x    # store x -values for graphing purposes (initial)
ftrace <- f(x) # store y-values (function eval at x) for graphing purposes (initial)
stepFactor <- 0.6 # learning rate 'alpha'
for (step in 1:100) {
x <- x - stepFactor * grad(x) # gradient descent update
xtrace <- c(xtrace, x)      # update for graph
ftrace <- c(ftrace, f(x))   # update for graph
}
lines (xtrace, ftrace, type="b", col="blue")
text (0.5, 6, "Gradient Descent", col="blue", pos= 4)
# print final value of x
print(length(xtrace))
print(x) # x converges to 2.0
xs <- seq(0, 4,len=20) # create some values
# define the function we want to optimize
f <-  function(x) {
1.2 * (x-2)^2 + 3.2
}
# plot the function
plot(xs, f (xs),
type = "l",
xlab = "x",
ylab = expression(1.2(x-2)^2 +3.2))
# calculate the gradient df/dx
grad <- function(x){
1.2*2*(x-2)
}
# df/dx = 2.4(x-2), if x = 2 then 2.4(2-2) = 0
# The actual solution we will approximate with gradeint descent
# is  x = 2 as depicted in the plot below
lines (c(2,2), c(3,8), col="green", lty=2)
text (2.1,7, "Closed-form solution", col="red", pos=4)
# gradient descent implementation
x <- 0.1       # initialize the first guess for x-value
xtrace <- x    # store x -values for graphing purposes (initial)
ftrace <- f(x) # store y-values (function eval at x) for graphing purposes (initial)
stepFactor <- 0.6 # learning rate 'alpha'
for (step in 1:100) {
x <- x - stepFactor * grad(x) # gradient descent update
xtrace <- c(xtrace, x)      # update for graph
ftrace <- c(ftrace, f(x))   # update for graph
}
lines (xtrace, ftrace, type="b", col="blue")
text (0.5, 6, "Gradient Descent", col="blue", pos= 4)
# print final value of x
print(length(xtrace))
print(length(ftrace))
print(x) # x converges to 2.0
f <-function(x) {
1.2 * (x−2)^2 + 3.2
}
grad <− function(x) {
1.2 * 2 * (x−2)
}
secondGrad <− function(x) {
2.4
}
xs <− seq(0,4,len=20)
plot (xs , f (xs ), type=”l”,xlab=”x”,ylab=expression(1.2(x−2)ˆ2 +3.2))
xs <− seq(0,4,len=20)
plot (xs , f(xs), type=”l”,xlab=”x”,ylab=expression(1.2(x−2)^2 +3.2))
xs <− seq(0,4,len=20)
plot (xs , f(xs),
type = ”l”,
f <- function(x) {
1.2 * (x−2)^2 + 3.2
}
grad <− function(x) {
1.2 * 2 * (x−2)
}
secondGrad <− function(x) {
2.4
}
xs <− seq(0,4,len=20)
plot(xs, f(xs),
type = ”l”,
xs <− seq(0,4,len=20)
plot(xs, f(xs),
type = ”l”,
xs <− seq(0,4, len=20)
plot(xs, f(xs),
type = ”l”,
plot(xs, f(xs))
plot(xs, f(xs), type = "l")
plot(xs, f(xs), type = "l", xlab = "x")
plot(xs, f(xs), type = "l", xlab = "x", ylab = expression(1.2(x−2)^2 +3.2))
xs <− seq(0,4, len=20)
plot(xs, f(xs),
type = "l",
xlab = "x",
ylab = expression(1.2(x−2)^2 +3.2))
### df/dx = 2.4(x−2)
### df/dx = 0 −−−> 0 = 2.4x − 4.8 −−−> x = 2
lines (c (2,2), c (3,8), col =”red”,lty=2)
xs <− seq(0,4, len=20)
plot(xs, f(xs),
type = "l",
xlab = "x",
ylab = expression(1.2(x−2)^2 +3.2))
### df/dx = 2.4(x−2)
### df/dx = 0 −−−> 0 = 2.4x − 4.8 −−−> x = 2
lines (c (2,2), c (3,8), col = "red"", lty =2)
text (2.1,7, "Closed−form solution", col="red", pos=4)
xs <− seq(0,4, len=20)
plot(xs, f(xs),
type = "l",
xlab = "x",
ylab = expression(1.2(x−2)^2 +3.2))
### df/dx = 2.4(x−2)
### df/dx = 0 −−−> 0 = 2.4x − 4.8 −−−> x = 2
lines (c (2,2), c (3,8), col = "red", lty =2)
text (2.1,7, "Closed−form solution", col="red", pos=4)
### gradient descent
x <− 0.1
xtrace <− x
ftrace <− f(x)
stepFactor <− 0.6 ### try larger and smaller values (0.8 and 0.01)
for (step in 1:100) {
x <− x − stepFactor * grad(x)
xtrace <− c(xtrace,x)
ftrace <− c(ftrace,f(x))
}lines ( xtrace , ftrace , type=”b”,col=”blue”)
xs <− seq(0,4, len=20)
plot(xs, f(xs),
type = "l",
xlab = "x",
ylab = expression(1.2(x−2)^2 +3.2))
### df/dx = 2.4(x−2)
### df/dx = 0 −−−> 0 = 2.4x − 4.8 −−−> x = 2
lines (c (2,2), c (3,8), col = "red", lty =2)
text (2.1,7, "Closed−form solution", col="red", pos=4)
### gradient descent
x <− 0.1
xtrace <− x
ftrace <− f(x)
stepFactor <− 0.6 ### try larger and smaller values (0.8 and 0.01)
for (step in 1:100) {
x <− x − stepFactor * grad(x)
xtrace <− c(xtrace,x)
ftrace <− c(ftrace,f(x))
}
lines ( xtrace , ftrace , type="b", col="blue")
text (0.5,6, "Gradient Descent",col=”blue”,pos=4)
xs <− seq(0,4, len=20)
plot(xs, f(xs),
type = "l",
xlab = "x",
ylab = expression(1.2(x−2)^2 +3.2))
### df/dx = 2.4(x−2)
### df/dx = 0 −−−> 0 = 2.4x − 4.8 −−−> x = 2
lines (c (2,2), c (3,8), col = "red", lty =2)
text (2.1,7, "Closed−form solution", col="red", pos=4)
### gradient descent
x <− 0.1
xtrace <− x
ftrace <− f(x)
stepFactor <− 0.6 ### try larger and smaller values (0.8 and 0.01)
for (step in 1:100) {
x <− x − stepFactor * grad(x)
xtrace <− c(xtrace,x)
ftrace <− c(ftrace,f(x))
}
lines ( xtrace , ftrace , type="b", col="blue")
text (0.5,6, "Gradient Descent", col = "blue", pos=4)
source("./R/gradientDescents.R")
x <− 0.1
result <− steepest(x, f, grad , stepsize =0.6, nIterations =100, xtracep=TRUE, ftracep=TRUE)
plot (xs, f(xs ), type="l",xlab="x", ylab=expression(1.2(x−2)^2 +3.2))
lines ( result $xtrace , result $ ftrace , type="b",col="blue")
text (0.5,6, "Gradient Descent with steepest ()", col ="blue",pos=4)
source("./R/gradientDescents.R")
x <− 0.1
result <− steepest(x, f,
grad,
stepsize = 0.6,
nIterations = 100,
xtracep = TRUE,
ftracep = TRUE)
plot (xs, f(xs), type = "l", xlab = "x", ylab = expression(1.2(x−2)^2 +3.2))
lines(result$xtrace, result$ftrace , type ="b", col ="blue")
text (0.5,6, "Gradient Descent with steepest ()", col ="blue",pos=4)
plot(xs, f(xs ), type= "l", xlab="x", ylab=expression(1.2(x−2)^2 +3.2))
x <− 0.1
xtrace <− x
ftrace <− f(x)
for (step in 1:100) {
x <− x − grad(x)/secondGrad(x)
xtrace <− c(xtrace,x)
ftrace <− c(ftrace,f(x))
}
lines(xtrace, ftrace , type="b",col="blue")
text (0.5,6, "Newton's Gradient Descent",col="blue",pos=4)
source("./R/gradientDescents.R")
x <− 0.1
result <− scg(x, f,
grad ,
nIterations =100,
xtracep=TRUE,
ftracep=TRUE)
plot (xs , f (xs ), type="l",xlab="x",ylab=expression(1.2(x−2)^2 +3.2))
lines (result$xtrace, result$ftrace , type ="b", col="blue")
text (0.5,6, "Gradient Descent with scg ()", col ="blue",pos=4)
source("./R/gradientDescents.R")
x <− 0.1
result <− scg(x, f,
grad ,
nIterations = 100,
xtracep = TRUE,
ftracep = TRUE)
plot(xs, f (xs), type = "l", xlab = "x",ylab=expression(1.2(x−2)^2 +3.2))
lines(result$xtrace, result$ftrace, type = "b", col = "blue")
text(0.5, 6, "Gradient Descent with scg ()", col = "blue", pos = 4)
plot(xs, f(xs), type = "l", xlab = "x", ylab = expression(1.2(x−2)^2 +3.2))
x <− 0.1
xtrace <− x
ftrace <− f(x)
for (step in 1:100) {
x <− x − grad(x) / secondGrad(x)
xtrace <− c(xtrace,x)
ftrace <− c(ftrace,f(x))
}
lines(xtrace, ftrace, type = "b", col = "blue")
text (0.5, 6, "Newton's Gradient Descent", col = "blue", pos = 4)
f <- function(x) {
1.2 * (x−2)^2 + 3.2
}
grad <− function(x) {
1.2 * 2 * (x−2)
}
secondGrad <− function(x) {
2.4
}
xs <− seq(0,4, len = 20)
plot(xs, f(xs),
type = "l",
xlab = "x",
ylab = expression(1.2(x−2)^2 +3.2))
### df/dx = 2.4(x−2)
### df/dx = 0 −−−> 0 = 2.4x − 4.8 −−−> x = 2
lines (c(2,2), c(3,8), col = "red", lty = 2)
text (2.1, 7, "Closed−form solution", col = "red", pos = 4)
### gradient descent
x <− 0.1
xtrace <− x
ftrace <− f(x)
stepFactor <− 0.6 ### try larger and smaller values (0.8 and 0.01)
for (step in 1:100) {
x <− x − stepFactor * grad(x)
xtrace <− c(xtrace, x)
ftrace <− c(ftrace, f(x))
}
lines( xtrace , ftrace , type="b", col = "blue")
text(0.5, 6, "Gradient Descent", col = "blue", pos = 4)
source("./R/gradientDescents.R")
x <− 0.1
result <− steepest(x, f,
grad,
stepsize = 0.6,
nIterations = 100,
xtracep = TRUE,
ftracep = TRUE)
plot(xs, f(xs), type = "l", xlab = "x", ylab = expression(1.2(x−2)^2 +3.2))
lines(result$xtrace, result$ftrace , type = "b", col = "blue")
text (0.5, 6, "Gradient Descent with steepest ()", col = "blue", pos = 4)
source("./R/gradientDescents.R")
x <− 0.1
result <− scg(x, f,
grad,
nIterations = 100,
xtracep = TRUE,
ftracep = TRUE)
plot(xs, f (xs), type = "l", xlab = "x", ylab = expression(1.2(x−2)^2 +3.2))
lines(result$xtrace, result$ftrace, type = "b", col = "blue")
text(0.5, 6, "Gradient Descent with scg ()", col = "blue", pos = 4)
knitr::opts_chunk$set(echo = TRUE, comment = NA, error = TRUE)
f <- function(x) {
1.2 * (x−2)^2 + 3.2
}
grad <− function(x) {
1.2 * 2 * (x−2)
}
secondGrad <− function(x) {
2.4
}
xs <− seq(0,4, len = 20)
plot(xs, f(xs),
type = "l",
xlab = "x",
ylab = expression(1.2(x−2)^2 +3.2))
### df/dx = 2.4(x−2)
### df/dx = 0 −−−> 0 = 2.4x − 4.8 −−−> x = 2
lines (c(2,2), c(3,8), col = "red", lty = 2)
text (2.1, 7, "Closed−form solution", col = "red", pos = 4)
### gradient descent
x <− 0.1
xtrace <− x
ftrace <− f(x)
stepFactor <− 0.6 ### try larger and smaller values (0.8 and 0.01)
for (step in 1:100) {
x <− x − stepFactor * grad(x)
xtrace <− c(xtrace, x)
ftrace <− c(ftrace, f(x))
}
lines( xtrace , ftrace , type="b", col = "blue")
text(0.5, 6, "Gradient Descent", col = "blue", pos = 4)
source("./R/gradientDescents.R")
x <− 0.1
result <− steepest(x, f,
grad,
stepsize = 0.6,
nIterations = 100,
xtracep = TRUE,
ftracep = TRUE)
plot(xs, f(xs), type = "l", xlab = "x", ylab = expression(1.2(x−2)^2 +3.2))
lines(result$xtrace, result$ftrace , type = "b", col = "blue")
text(0.5, 6, "Gradient Descent with steepest ()", col = "blue", pos = 4)
plot(xs, f(xs), type = "l", xlab = "x", ylab = expression(1.2(x−2)^2 +3.2))
x <− 0.1
xtrace <− x
ftrace <− f(x)
for (step in 1:100) {
x <− x − grad(x) / secondGrad(x)
xtrace <− c(xtrace,x)
ftrace <− c(ftrace,f(x))
}
lines(xtrace, ftrace, type = "b", col = "blue")
text(0.5, 6, "Newton's Gradient Descent", col = "blue", pos = 4)
source("./R/gradientDescents.R")
x <− 0.1
result <− scg(x, f,
grad,
nIterations = 100,
xtracep = TRUE,
ftracep = TRUE)
plot(xs, f (xs), type = "l", xlab = "x", ylab = expression(1.2(x−2)^2 +3.2))
lines(result$xtrace, result$ftrace, type = "b", col = "blue")
text(0.5, 6, "Gradient Descent with scg ()", col = "blue", pos = 4)
install.packages("RcppOctave")
install.packages("RcppOctave")
install.packages("RcppOctave", source)
install.packages("RcppOctave", type="source")
<<<<<<< HEAD
src <- '
Rcpp::NumericMatrix Am(A);
int nrows = Am.nrow();
for (int j = 1; j < nrows; j++) {
Am(j,_) = Am(j,_) + Am(j-1,_);
}
return Am;
'
fun <- cxxfunction(signature(A = "numeric"), body = src, plugin="Rcpp")
src <- '
Rcpp::NumericMatrix Am(A);
int nrows = Am.nrow();
for (int j = 1; j < nrows; j++) {
Am(j,_) = Am(j,_) + Am(j-1,_);
}
return Am;
'
fun <- cxxfunction(signature(A = "numeric"), body = src, plugin="Rcpp")
library(Rcpp)
src <- '
Rcpp::NumericMatrix Am(A);
int nrows = Am.nrow();
for (int j = 1; j < nrows; j++) {
Am(j,_) = Am(j,_) + Am(j-1,_);
}
return Am;
'
fun <- cxxfunction(signature(A = "numeric"), body = src, plugin="Rcpp")
library(Rcpp)
library(inline)
src <- '
Rcpp::NumericMatrix Am(A);
int nrows = Am.nrow();
for (int j = 1; j < nrows; j++) {
Am(j,_) = Am(j,_) + Am(j-1,_);
}
return Am;
'
fun <- cxxfunction(signature(A = "numeric"), body = src, plugin="Rcpp")
=======
>>>>>>> 4cb3b50f466884cf532503d6d4d8d704b13812d1
>>>>>>> 2bcf3c4e6653cee6ff3ff3fd1191080c10c6a506
